{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b97c355",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title: Score Predictor\n",
    "description: Visualizing Percentile Scores with Machine Learning\n",
    "permalink: /scoreblog/\n",
    "toc: false\n",
    "comments: true\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5295df62",
   "metadata": {},
   "source": [
    "\n",
    "<h1> Purpose </h1>\n",
    "\n",
    "This project helps students understand how their raw scores on tests compare to a population. We do this by converting raw scores into **percentile ranks** using a machine learning technique called **Quantile Transformation**.\n",
    "\n",
    "<h1> Data Collection </h1>\n",
    "\n",
    "We train the model using a dataset of prior student scores. Each record includes:\n",
    "\n",
    "- Multiple Choice Questions (MCQ) score\n",
    "- Free Response Questions (FRQ) score\n",
    "\n",
    "Here’s a simplified example:\n",
    "\n",
    "csv\n",
    "mcq,frq\n",
    "12,3\n",
    "18,4\n",
    "20,4\n",
    "22,5\n",
    "15,2\n",
    "10,1\n",
    "24,5\n",
    "17,3\n",
    "19,4\n",
    "\n",
    "In the real application, we load this dataset dynamically from a CSV file:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0930edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.path.dirname(__file__), 'synthetic_data_science_scores.csv')\n",
    "data = pd.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee066718",
   "metadata": {},
   "source": [
    "<h1> Processing </h1>\n",
    "To calculate percentiles, we use QuantileTransformer from scikit-learn, which maps raw scores to a uniform distribution:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a31bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = data.shape[0]\n",
    "n_quantiles = min(1000, n_samples)\n",
    "\n",
    "mcq_transformer = QuantileTransformer(n_quantiles=n_quantiles, output_distribution='uniform')\n",
    "frq_transformer = QuantileTransformer(n_quantiles=n_quantiles, output_distribution='uniform')\n",
    "\n",
    "mcq_transformer.fit(data[['mcq']])\n",
    "frq_transformer.fit(data[['frq']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68aae6a",
   "metadata": {},
   "source": [
    "This allows us to normalize student scores against the dataset, making it easy to calculate relative performance.\n",
    "<h1> Backend API </h1>\n",
    "Our Flask backend exposes an API endpoint where users submit their scores and receive percentiles in return:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1091ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "@score_api.route('/api/percentile', methods=['POST'])\n",
    "def calculate_percentile():\n",
    "    scores = request.get_json()\n",
    "    mcq_score = scores.get('mcq')\n",
    "    frq_score = scores.get('frq')\n",
    "\n",
    "    if mcq_score is None or frq_score is None:\n",
    "        return jsonify({'error': 'Missing mcq or frq scores'}), 400\n",
    "\n",
    "    score = Score(mcq_score, frq_score)\n",
    "    return jsonify({\n",
    "        'mcq_percentile': score.mcq_percentile(),\n",
    "        'frq_percentile': score.frq_percentile()\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f8d45",
   "metadata": {},
   "source": [
    "The Score class wraps the transformation logic:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc34928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Score:\n",
    "    def __init__(self, mcq, frq):\n",
    "        self.mcq = mcq\n",
    "        self.frq = frq\n",
    "\n",
    "    def mcq_percentile(self):\n",
    "        percentile = mcq_transformer.transform([[self.mcq]])[0][0]\n",
    "        return float(np.round(percentile * 100, 2))\n",
    "\n",
    "    def frq_percentile(self):\n",
    "        percentile = frq_transformer.transform([[self.frq]])[0][0]\n",
    "        return float(np.round(percentile * 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae97221",
   "metadata": {},
   "source": [
    "\n",
    "<h1> Frontend Output </h1>\n",
    "Once the user inputs scores and submits the form, the frontend calls /api/percentile and displays:\n",
    "- MCQ Percentile\n",
    "- FRQ Percentile\n",
    "- Combined estimate and predicted AP score (1–5)\n",
    "\n",
    "<h1> Example Output </h1>\n",
    "If the user enters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e25de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "{\n",
    "  \"mcq\": 20,\n",
    "  \"frq\": 4\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa638ff",
   "metadata": {},
   "source": [
    "The API may respond with:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8010ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "{\n",
    "  \"mcq_percentile\": 88.5,\n",
    "  \"frq_percentile\": 77.2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90898d66",
   "metadata": {},
   "source": [
    "<h1> Visual Display </h1>\n",
    "These scores are shown on a bar graph (using Chart.js) to visually represent relative performance.\n",
    "         |       |            |\n",
    "Component|\tScore|\tPercentile|\n",
    "MCQ|\t20|\t88.5%|\n",
    "FRQ|\t4|\t77.2%|\n",
    "Total|\t—|  82.8%|\n",
    "\n",
    "<h1> Takeaways </h1>\n",
    "This project turns raw exam scores into meaningful insights using data transformation and visualization. It's especially useful for students preparing for standardized tests, helping them understand how they compare to others.\n",
    "\n",
    "<h1> Roadmap </h1>\n",
    "Features to add next:\n",
    "- Export percentile history\n",
    "- Upload custom score datasets\n",
    "- Train a model to directly classify scores into AP levels"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
